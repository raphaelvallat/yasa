<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>yasa.art_detect &#8212; yasa 0.6.0 documentation</title>
    <link rel="stylesheet" href="../_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="../_static/js/jquery-1.12.4.min.js "></script>
<script type="text/javascript" src="../_static/js/jquery-fix.js "></script>
<script type="text/javascript" src="../_static/bootstrap-3.4.1/js/bootstrap.min.js "></script>
<script type="text/javascript" src="../_static/bootstrap-sphinx.js "></script>

  </head><body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../index.html"><span><img src="../_static/yasa_128x128.png"></span>
          yasa</a>
        <span class="navbar-text navbar-version pull-left"><b>0.6.0</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="../api.html">API</a></li>
                <li><a href="../quickstart.html">Quickstart</a></li>
                <li><a href="../faq.html">FAQ</a></li>
                <li><a href="../changelog.html">What's new</a></li>
                <li><a href="../contributing.html">Contribute</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"></ul>
</li>
              
            
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="body col-md-12 content" role="main">
      
  <div class="section" id="yasa-art-detect">
<h1>yasa.art_detect<a class="headerlink" href="#yasa-art-detect" title="Permalink to this headline">¶</a></h1>
<dl class="py function">
<dt id="yasa.art_detect">
<code class="sig-prename descclassname">yasa.</code><code class="sig-name descname">art_detect</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">sf</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">window</span><span class="o">=</span><span class="default_value">5</span></em>, <em class="sig-param"><span class="n">hypno</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">include</span><span class="o">=</span><span class="default_value">1, 2, 3, 4</span></em>, <em class="sig-param"><span class="n">method</span><span class="o">=</span><span class="default_value">'covar'</span></em>, <em class="sig-param"><span class="n">threshold</span><span class="o">=</span><span class="default_value">3</span></em>, <em class="sig-param"><span class="n">n_chan_reject</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/yasa/detection.html#art_detect"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#yasa.art_detect" title="Permalink to this definition">¶</a></dt>
<dd><p>Automatic artifact rejection.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.2.0.</span></p>
</div>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>data</strong><span class="classifier">array_like</span></dt><dd><p>Single or multi-channel EEG data.
Unit must be uV and shape <em>(n_chan, n_samples)</em>.
Can also be a <a class="reference external" href="https://mne.tools/stable/generated/mne.io.BaseRaw.html#mne.io.BaseRaw" title="(in MNE v0.24)"><code class="xref py py-class docutils literal notranslate"><span class="pre">mne.io.BaseRaw</span></code></a>, in which case <code class="docutils literal notranslate"><span class="pre">data</span></code>
and <code class="docutils literal notranslate"><span class="pre">sf</span></code> will be automatically extracted,
and <code class="docutils literal notranslate"><span class="pre">data</span></code> will also be automatically converted from Volts (MNE)
to micro-Volts (YASA).</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p><code class="docutils literal notranslate"><span class="pre">data</span></code> must only contains EEG channels. Please make sure to
exclude any EOG, EKG or EMG channels.</p>
</div>
</dd>
<dt><strong>sf</strong><span class="classifier">float</span></dt><dd><p>Sampling frequency of the data in Hz.
Can be omitted if <code class="docutils literal notranslate"><span class="pre">data</span></code> is a <a class="reference external" href="https://mne.tools/stable/generated/mne.io.BaseRaw.html#mne.io.BaseRaw" title="(in MNE v0.24)"><code class="xref py py-class docutils literal notranslate"><span class="pre">mne.io.BaseRaw</span></code></a> object.</p>
</dd>
<dt><strong>window</strong><span class="classifier">float</span></dt><dd><p>The window length (= resolution) for artifact rejection, in seconds.
Default to 5 seconds. Shorter windows (e.g. 1 or 2-seconds) will
drastically increase computation time when <code class="docutils literal notranslate"><span class="pre">method='covar'</span></code>.</p>
</dd>
<dt><strong>hypno</strong><span class="classifier">array_like</span></dt><dd><p>Sleep stage (hypnogram). If the hypnogram is passed, the
detection will be applied separately for each of the stages defined in
<code class="docutils literal notranslate"><span class="pre">include</span></code>.</p>
<p>The hypnogram must have the same number of samples as <code class="docutils literal notranslate"><span class="pre">data</span></code>.
To upsample your hypnogram, please refer to
<a class="reference internal" href="yasa.hypno_upsample_to_data.html#yasa.hypno_upsample_to_data" title="yasa.hypno_upsample_to_data"><code class="xref py py-func docutils literal notranslate"><span class="pre">yasa.hypno_upsample_to_data()</span></code></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The default hypnogram format in YASA is a 1D integer
vector where:</p>
<ul class="simple">
<li><p>-2 = Unscored</p></li>
<li><p>-1 = Artefact / Movement</p></li>
<li><p>0 = Wake</p></li>
<li><p>1 = N1 sleep</p></li>
<li><p>2 = N2 sleep</p></li>
<li><p>3 = N3 sleep</p></li>
<li><p>4 = REM sleep</p></li>
</ul>
</div>
</dd>
<dt><strong>include</strong><span class="classifier">tuple, list or int</span></dt><dd><p>Sleep stages in <code class="docutils literal notranslate"><span class="pre">hypno</span></code> on which to perform the artifact rejection.
The default is <code class="docutils literal notranslate"><span class="pre">hypno=(1,</span> <span class="pre">2,</span> <span class="pre">3,</span> <span class="pre">4)</span></code>, meaning that the artifact
rejection is applied separately for all sleep stages, excluding wake.
This parameter has no effect when <code class="docutils literal notranslate"><span class="pre">hypno</span></code> is None.</p>
</dd>
<dt><strong>method</strong><span class="classifier">str</span></dt><dd><p>Artifact detection method (see Notes):</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">'covar'</span></code> : Covariance-based, default for 4+ channels data</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'std'</span></code> : Standard-deviation-based, default for single-channel data</p></li>
</ul>
</dd>
<dt><strong>threshold</strong><span class="classifier">float</span></dt><dd><p>The number of standard deviations above or below which an
epoch is considered an artifact. Higher values will result in a more
conservative detection, i.e. less rejected epochs.</p>
</dd>
<dt><strong>n_chan_reject</strong><span class="classifier">int</span></dt><dd><p>The number of channels that must be below or above <code class="docutils literal notranslate"><span class="pre">threshold</span></code> on any
given epochs to consider this epoch as an artefact when
<code class="docutils literal notranslate"><span class="pre">method='std'</span></code>. The default is 1, which means that the epoch will
be marked as artifact as soon as one channel is above or below the
threshold. This may be too conservative when working with a large
number of channels (e.g.hdEEG) in which case users can increase
<code class="docutils literal notranslate"><span class="pre">n_chan_reject</span></code>. Note that this parameter only has an effect
when <code class="docutils literal notranslate"><span class="pre">method='std'</span></code>.</p>
</dd>
<dt><strong>verbose</strong><span class="classifier">bool or str</span></dt><dd><p>Verbose level. Default (False) will only print warning and error
messages. The logging levels are ‘debug’, ‘info’, ‘warning’, ‘error’,
and ‘critical’. For most users the choice is between ‘info’
(or <code class="docutils literal notranslate"><span class="pre">verbose=True</span></code>) and warning (<code class="docutils literal notranslate"><span class="pre">verbose=False</span></code>).</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.2.0.</span></p>
</div>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>art_epochs</strong><span class="classifier">array_like</span></dt><dd><p>1-D array of shape <em>(n_epochs)</em> where 1 = Artefact and 0 = Good.</p>
</dd>
<dt><strong>zscores</strong><span class="classifier">array_like</span></dt><dd><p>Array of z-scores, shape is <em>(n_epochs)</em> if <code class="docutils literal notranslate"><span class="pre">method='covar'</span></code> and
<em>(n_epochs, n_chan)</em> if <code class="docutils literal notranslate"><span class="pre">method='std'</span></code>.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>This function will only detect major body artefacts present on the EEG
channel. It will not detect EKG contamination or eye blinks. For more
artifact rejection tools, please refer to the <a class="reference external" href="https://mne.tools/stable/auto_tutorials/preprocessing/plot_10_preprocessing_overview.html">MNE Python package</a>.</p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>For best performance, apply this function on pre-staged data and make
sure to pass the hypnogram.
Sleep stages have very different EEG signatures
and the artifect rejection will be much more accurate when applied
separately on each sleep stage.</p>
</div>
<p>We provide below a short description of the different methods. For
multi-channel data, and if computation time is not an issue, we recommend
using <code class="docutils literal notranslate"><span class="pre">method='covar'</span></code> which uses a clustering approach on
variance-covariance matrices, and therefore takes into account
not only the variance in each channel and each epoch, but also the
inter-relationship (covariance) between channel.</p>
<p><code class="docutils literal notranslate"><span class="pre">method='covar'</span></code> is however not supported for single-channel EEG or when
less than 4 channels are present in <code class="docutils literal notranslate"><span class="pre">data</span></code>. In these cases, one can
use the much faster <code class="docutils literal notranslate"><span class="pre">method='std'</span></code> which is simply based on a z-scoring
of the log-transformed standard deviation of each channel and each epoch.</p>
<p><strong>1/ Covariance-based multi-channel artefact rejection</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">method='covar'</span></code> is essentially a wrapper around the
<a class="reference external" href="https://pyriemann.readthedocs.io/en/latest/generated/pyriemann.clustering.Potato.html#pyriemann.clustering.Potato" title="(in pyRiemann v0.2.8.dev)"><code class="xref py py-class docutils literal notranslate"><span class="pre">pyriemann.clustering.Potato</span></code></a> class implemented in the
<a class="reference external" href="https://pyriemann.readthedocs.io/en/latest/index.html">pyRiemann package</a>.</p>
<p>The main idea of this approach is to estimate a reference covariance
matrix <span class="math notranslate nohighlight">\(\bar{C}\)</span> (for each sleep stage separately if <code class="docutils literal notranslate"><span class="pre">hypno</span></code> is
present) and reject every epoch which is too far from this reference
matrix.
The distance of the covariance matrix of the current epoch <span class="math notranslate nohighlight">\(C\)</span>
from the reference matrix is calculated using Riemannian
geometry, which is more adapted than Euclidean geometry for
symmetric positive definite covariance matrices:</p>
<div class="math notranslate nohighlight">
\[d = {\left( \sum_i \log(\lambda_i)^2 \right)}^{-1/2}\]</div>
<p>where <span class="math notranslate nohighlight">\(\lambda_i\)</span> are the joint eigenvalues of <span class="math notranslate nohighlight">\(C\)</span> and
<span class="math notranslate nohighlight">\(\bar{C}\)</span>. The epoch with covariance matric <span class="math notranslate nohighlight">\(C\)</span>
will be marked as an artifact if the distance <span class="math notranslate nohighlight">\(d\)</span>
is greater than a threshold <span class="math notranslate nohighlight">\(T\)</span>
(typically 2 or 3 standard deviations).
<span class="math notranslate nohighlight">\(\bar{C}\)</span> is iteratively estimated using a clustering approach.</p>
<p><strong>2/ Standard-deviation-based single and multi-channel artefact rejection</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">method='std'</span></code> is a much faster and straightforward approach which
is simply based on the distribution of the standard deviations of each
epoch. Specifically, one first calculate the standard
deviations of each epoch and each channel. Then, the resulting array of
standard deviations is log-transformed and z-scored (for each sleep
stage separately if <code class="docutils literal notranslate"><span class="pre">hypno</span></code> is present). Any epoch with one or more
channel exceeding the threshold will be marked as artifact.</p>
<p>Note that this approach is more sensitive to noise and/or the influence of
one bad channel (e.g. electrode fell off at some point during the night).
We therefore recommend that you visually inspect and remove any bad
channels prior to using this function.</p>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Barachant, A., Andreev, A., &amp; Congedo, M. (2013). <a class="reference external" href="https://hal.archives-ouvertes.fr/hal-00781701/">The Riemannian
Potato: an automatic and adaptive artifact detection method for online
experiments using Riemannian geometry.</a> TOBI
Workshop lV, 19–20.</p></li>
<li><p>Barthélemy, Q., Mayaud, L., Ojeda, D., &amp; Congedo, M. (2019).
<a class="reference external" href="https://doi.org/10.1109/TNSRE.2019.2893113">The Riemannian Potato Field: A Tool for Online Signal Quality Index of
EEG.</a>
IEEE Transactions on Neural Systems and Rehabilitation Engineering:
A Publication of the IEEE Engineering in Medicine and Biology Society,
27(2), 244–255.</p></li>
<li><p><a class="reference external" href="https://pyriemann.readthedocs.io/en/latest/index.html">https://pyriemann.readthedocs.io/en/latest/index.html</a></p></li>
</ul>
<p class="rubric">Examples</p>
<p>For an example of how to run the detection, please refer to
<a class="reference external" href="https://github.com/raphaelvallat/yasa/blob/master/notebooks/13_artifact_rejection.ipynb">https://github.com/raphaelvallat/yasa/blob/master/notebooks/13_artifact_rejection.ipynb</a></p>
</dd></dl>

</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
        <br/>
        
      
    </p>
    <p>
        &copy; Copyright 2018-2022, Dr. Raphael Vallat, Center for Human Sleep Science, UC Berkeley.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.0.0.<br/>
    </p>
  </div>
</footer>
  </body>
</html>