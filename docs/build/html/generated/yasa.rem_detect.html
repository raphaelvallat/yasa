<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>yasa.rem_detect &#8212; yasa 0.6.5 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/bootstrap-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="../_static/js/jquery-1.12.4.min.js"></script>
<script type="text/javascript" src="../_static/js/jquery-fix.js"></script>
<script type="text/javascript" src="../_static/bootstrap-3.4.1/js/bootstrap.min.js"></script>
<script type="text/javascript" src="../_static/bootstrap-sphinx.js"></script>

  </head><body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../index.html"><span><img src="../_static/yasa_128x128.png"></span>
          yasa</a>
        <span class="navbar-text navbar-version pull-left"><b>0.6.5</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="../api.html">API</a></li>
                <li><a href="../quickstart.html">Quickstart</a></li>
                <li><a href="../faq.html">FAQ</a></li>
                <li><a href="../changelog.html">What's new</a></li>
                <li><a href="../contributing.html">Contribute</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"></ul>
</li>
              
            
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="body col-md-12 content" role="main">
      
  <section id="yasa-rem-detect">
<h1>yasa.rem_detect<a class="headerlink" href="#yasa-rem-detect" title="Permalink to this headline">¶</a></h1>
<dl class="py function">
<dt class="sig sig-object py" id="yasa.rem_detect">
<span class="sig-prename descclassname"><span class="pre">yasa.</span></span><span class="sig-name descname"><span class="pre">rem_detect</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loc</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">roc</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sf</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hypno</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">amplitude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(50,</span> <span class="pre">325)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">duration</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.3,</span> <span class="pre">1.2)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">relative_prominence</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">freq_rem</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.5,</span> <span class="pre">5)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_outliers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/yasa/detection.html#rem_detect"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#yasa.rem_detect" title="Permalink to this definition">¶</a></dt>
<dd><p>Rapid eye movements (REMs) detection.</p>
<p>This detection requires both the left EOG (LOC) and right EOG (LOC).
The units of the data must be uV. The algorithm is based on an amplitude
thresholding of the negative product of the LOC and ROC
filtered signal.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.1.5.</span></p>
</div>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>loc, roc</strong><span class="classifier">array_like</span></dt><dd><p>Continuous EOG data (Left and Right Ocular Canthi, LOC / ROC) channels.
Unit must be uV.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The default unit of <a class="reference external" href="https://mne.tools/stable/generated/mne.io.BaseRaw.html#mne.io.BaseRaw" title="(in MNE v1.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">mne.io.BaseRaw</span></code></a> is Volts.
Therefore, if passing data from a <a class="reference external" href="https://mne.tools/stable/generated/mne.io.BaseRaw.html#mne.io.BaseRaw" title="(in MNE v1.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">mne.io.BaseRaw</span></code></a>,
make sure to use units=”uV” to get the data in micro-Volts, e.g.:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">raw</span><span class="o">.</span><span class="n">get_data</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="s2">&quot;uV&quot;</span><span class="p">)</span>  <span class="c1"># Make sure that data is in uV</span>
</pre></div>
</div>
</div>
</dd>
<dt><strong>sf</strong><span class="classifier">float</span></dt><dd><p>Sampling frequency of the data, in Hz.</p>
</dd>
<dt><strong>hypno</strong><span class="classifier">array_like</span></dt><dd><p>Sleep stage (hypnogram). If the hypnogram is loaded, the
detection will only be applied to the value defined in
<code class="docutils literal notranslate"><span class="pre">include</span></code> (default = REM sleep).</p>
<p>The hypnogram must have the same number of samples as <code class="docutils literal notranslate"><span class="pre">data</span></code>.
To upsample your hypnogram, please refer to
<a class="reference internal" href="yasa.hypno_upsample_to_data.html#yasa.hypno_upsample_to_data" title="yasa.hypno_upsample_to_data"><code class="xref py py-func docutils literal notranslate"><span class="pre">yasa.hypno_upsample_to_data()</span></code></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The default hypnogram format in YASA is a 1D integer
vector where:</p>
<ul class="simple">
<li><p>-2 = Unscored</p></li>
<li><p>-1 = Artefact / Movement</p></li>
<li><p>0 = Wake</p></li>
<li><p>1 = N1 sleep</p></li>
<li><p>2 = N2 sleep</p></li>
<li><p>3 = N3 sleep</p></li>
<li><p>4 = REM sleep</p></li>
</ul>
</div>
</dd>
<dt><strong>include</strong><span class="classifier">tuple, list or int</span></dt><dd><p>Values in <code class="docutils literal notranslate"><span class="pre">hypno</span></code> that will be included in the mask. The default is
(4), meaning that the detection is applied on REM sleep.
This has no effect when <code class="docutils literal notranslate"><span class="pre">hypno</span></code> is None.</p>
</dd>
<dt><strong>amplitude</strong><span class="classifier">tuple or list</span></dt><dd><p>Minimum and maximum amplitude of the peak of the REM.
Default is 50 uV to 325 uV.</p>
</dd>
<dt><strong>duration</strong><span class="classifier">tuple or list</span></dt><dd><p>The minimum and maximum duration of the REMs.
Default is 0.3 to 1.2 seconds.</p>
</dd>
<dt><strong>relative_prominence</strong><span class="classifier">float</span></dt><dd><p>Relative prominence used to detect the peaks. The actual prominence is computed
by multiplying relative prominence by the minimal amplitude. Default is 0.8.</p>
</dd>
<dt><strong>freq_rem</strong><span class="classifier">tuple or list</span></dt><dd><p>Frequency range of REMs. Default is 0.5 to 5 Hz.</p>
</dd>
<dt><strong>remove_outliers</strong><span class="classifier">boolean</span></dt><dd><p>If True, YASA will automatically detect and remove outliers REMs
using <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html#sklearn.ensemble.IsolationForest" title="(in scikit-learn v1.5)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.ensemble.IsolationForest</span></code></a>.
YASA uses a random seed (42) to ensure reproducible results.
Note that this step will only be applied if there are more than
50 detected REMs in the first place. Default to False.</p>
</dd>
<dt><strong>verbose</strong><span class="classifier">bool or str</span></dt><dd><p>Verbose level. Default (False) will only print warning and error
messages. The logging levels are ‘debug’, ‘info’, ‘warning’, ‘error’,
and ‘critical’. For most users the choice is between ‘info’
(or <code class="docutils literal notranslate"><span class="pre">verbose=True</span></code>) and warning (<code class="docutils literal notranslate"><span class="pre">verbose=False</span></code>).</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.2.0.</span></p>
</div>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl>
<dt><strong>rem</strong><span class="classifier"><a class="reference internal" href="yasa.REMResults.html#yasa.REMResults" title="yasa.REMResults"><code class="xref py py-class docutils literal notranslate"><span class="pre">yasa.REMResults</span></code></a></span></dt><dd><p>To get the full detection dataframe, use:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rem</span> <span class="o">=</span> <span class="n">rem_detect</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rem</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
<p>This will give a <a class="reference external" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v2.2.2)"><code class="xref py py-class docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code></a> where each row is a
detected REM and each column is a parameter (= property).
To get the average parameters sleep stage:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rem</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">grp_stage</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The parameters that are calculated for each REM are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">'Start'</span></code>: Start of each detected REM, in seconds from the
beginning of data.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'Peak'</span></code>: Location of the peak (in seconds of data)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'End'</span></code>: End time (in seconds)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'Duration'</span></code>: Duration (in seconds)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'LOCAbsValPeak'</span></code>: LOC absolute amplitude at REM peak (in uV)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'ROCAbsValPeak'</span></code>: ROC absolute amplitude at REM peak (in uV)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'LOCAbsRiseSlope'</span></code>: LOC absolute rise slope (in uV/s)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'ROCAbsRiseSlope'</span></code>: ROC absolute rise slope (in uV/s)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'LOCAbsFallSlope'</span></code>: LOC absolute fall slope (in uV/s)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'ROCAbsFallSlope'</span></code>: ROC absolute fall slope (in uV/s)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'Stage'</span></code>: Sleep stage (only if hypno was provided)</p></li>
</ul>
<p>Note that all the output parameters are computed on the filtered LOC and
ROC signals.</p>
<p>For better results, apply this detection only on artefact-free REM sleep.</p>
<p class="rubric">References</p>
<p>The rapid eye movements detection algorithm is based on:</p>
<ul class="simple">
<li><p>Agarwal, R., Takeuchi, T., Laroche, S., &amp; Gotman, J. (2005).
<a class="reference external" href="https://doi.org/10.1109/TBME.2005.851512">Detection of rapid-eye movements in sleep studies.</a>
IEEE Transactions on Bio-Medical Engineering, 52(8), 1390–1396.</p></li>
<li><p>Yetton, B. D., Niknazar, M., Duggan, K. A., McDevitt, E. A., Whitehurst,
L. N., Sattari, N., &amp; Mednick, S. C. (2016). <a class="reference external" href="https://doi.org/10.1016/j.jneumeth.2015.11.015">Automatic detection of
rapid eye movements (REMs): A machine learning approach.</a>
Journal of Neuroscience Methods, 259, 72–82.</p></li>
</ul>
<p class="rubric">Examples</p>
<p>For an example of how to run the detection, please refer to
<a class="reference external" href="https://github.com/raphaelvallat/yasa/blob/master/notebooks/07_REMs_detection.ipynb">https://github.com/raphaelvallat/yasa/blob/master/notebooks/07_REMs_detection.ipynb</a></p>
</dd></dl>

</section>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
        <br/>
        
      
    </p>
    <p>
        &copy; Copyright 2018-2024, Dr. Raphael Vallat, Center for Human Sleep Science, UC Berkeley.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.4.0.<br/>
    </p>
  </div>
</footer>
  </body>
</html>